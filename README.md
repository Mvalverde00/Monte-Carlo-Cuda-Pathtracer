# Results
The expected output is the rendered scene in an interactive window.  Once a sufficiently low level of variance in the output has been reached, an image can be exported using the "print screen" feature on windows (eventually a true 'export' option will be added, but for now "print screen" is more than sufficient for permanently saving renders).  Several renders created using the program can be found in the samples/ directory.  In case there are issues building the project, a short video showcasing the project in action can be seen here: https://www.youtube.com/watch?v=w0EvK9pR29w

Alternatively, here are some curated screenshots:

| <img src="https://github.com/Mvalverde00/Monte-Carlo-Cuda-Pathtracer/blob/master/results/spheres.png" width="400"> |
|:--:| 
| *The first image produced, using the scene from Ray Tracing in One Weekend.* |


| <img src="https://github.com/Mvalverde00/Monte-Carlo-Cuda-Pathtracer/blob/master/results/mirror_wall.png" width="400"> |
|:--:| 
| *A cornell box demonstrating reflections from metallic materials.* |

| <img src="https://github.com/Mvalverde00/Monte-Carlo-Cuda-Pathtracer/blob/master/results/glass_dragon.png" width="400"> |
|:--:| 
| *A glass rendition of the Stanford Dragon.  This is a lot of triangles and requires a BVH of some sort to render.* |

| <img src="https://github.com/Mvalverde00/Monte-Carlo-Cuda-Pathtracer/blob/master/results/sponza.png" width="400"> |
|:--:| 
| *A large scene to stress test the BVH system.* |

| <img src="https://github.com/Mvalverde00/Monte-Carlo-Cuda-Pathtracer/blob/master/results/large_scene.png" width="400"> |
|:--:| 
| *A ridiculously large scene (~3 Million triangles) to push the BVH system to its limit.  Rendered at about 1 sample per second using the SAH BVH.* |

# Usage Instructions
Required libraries are ImGUI, tinyobjloader, SDL2, GLM, and GLEW.  However these are all included in the dep/ folder, included in the submission.  The code was built using Visual Studio 2019, and the relevant visual studio solution and project files have been included, as well as the compiled .exe file (for Windows 10) that it produced, although I have no way of knowing if any of these things will actually work without any further adjustments on another computer.  If it does not work as-provided and you would like to run it for yourself, please let me know and I would be happy to help try and see what's going wrong.  Otherwise, there are samples produced using the program in the samples/ directory, as well as a demo youtube video here: https://www.youtube.com/watch?v=w0EvK9pR29w showcasing most of the features.

If you actually build the project yourself, you can run it by simply entering "CudaPathTracer.exe <RESOURCE_DIR>", where <RESOURCE_DIR> is the full path to the included resources/ directory.  The default simple sphere scene should work even without the correct resource dir, but all other scenes utilize triangle meshes and thus will absolutely need the correct resource directory to function.  For example, I run the program by typing "CudaPathTracer.exe F:\\cs179\\CudaPathTracer\\resources\\"  Note that you need to put a final backslash at the end!

# Project Description
As promised, I have developed a CUDA accelerated monte-carlo path tracing program, capable of handling indirect lighting, soft shadows, reflection and refraction, and caustics.  For now all scenes are hardcoded in. The renderer also utilizes OpenGL-CUDA interopability to progressively render the scene in a window, which can also be used to interact with the scene by moving or re-orienting the camera.  This also allows for a convenient debug view, with the ImGUI library being used to create a small overlay which displays rendering statistics/information and also has a toggleable option for showing all object normals.  Multiple scenes are included and can be switched between using the debug window.

# Performance Analysis
All testing was done on my desktop, which has a "Ryzen 9 5900x" CPU and a "RTX 3080" GPU.

I ran the base CPU demo on three different scenes-- a vanilla cornell box, an outdoor scene with lots of spheres (taken from Peter Shirley's "Raytracing in One Weekend"), and a similar outdoor scene but with complex triangle meshes containing about 600 triangles total (without a BVH tree or other acceleration structure, this is near the limit for an acceptable interactive framerate).  All scenes were rendered with 500 samples per pixel at a resolution of 1280x720, and a max recursive depth of 16.

In order to give the CPU a fighting chance, I added some simple parallelism to the render loop for the CPU demo, distributing the job of calculating a final color for each pixel across 12 threads.  The render times were 473 seconds for the Cornell Box, 322 seconds for the outdoor scene with spheres, and 1239 seconds for the outdoor scene with spheres and triangle meshes.  Additionally, I ran the Cornell Box scene a second time, single-threaded, and the resultant image took 3424 seconds to render!  This excessively long render time discouraged me from trying the other scenes with only 1 thread, but we can imagine that there will be a similar slowdown.

On the GPU side, there are two different kernels implementing the main "calculate what color should this pixel be based on how this ray travels through the scene" function, each of which offers a different advantage.  The first version of the kernel, "rayColor" located in "pathtrace.cu", is simply an iterative version of the corresponding recursive function from the CPU demo.  Using this version, and with the same resolution/max depth/samples as in the CPU benchmarks, the Cornell Box scene takes 23 seconds to render, the outdoor scene with spheres takes 35 seconds, and the outdoor scene with meshes takes 56 seconds to render.
Thus, we see a 148x improvement over the single threaded CPU in the Cornell Box scene, and an average 17x improvement over the 12 threaded CPU in all scenes.  It is interesting to see that the GPU struggles so heavily with speeding up the outdoor scene with spheres, which gains only a 9x speedup, whereas the cornell box and outdoor scene with complex triangle meshes both enjoy a 20x speedup over the 12-threaded CPU version.  This may be because in an outdoor scene, many paths with terminate very early and the entire kernel will be stuck waiting for the very few paths that have not yet terminated, suffering from extreme warp divergence.  This is also true in the outdoor scene with complex meshes, but the bottleneck there is definitely on calculating ray-object intersections, which the GPU is able to do much faster, hence the significant speedup.  Nevertheless, this highlights the negative impact that warp divergence can have on a scene, which leads to the next version of the kernel...

For the next version of the kernel, "rayColorLowerDivergence" located in "pathtrace.cu", we still follow largely the same algorithm, but now when a thread finishes tracing its path early, instead of breaking and waiting for other threads in the warp to finish we instead start a new path.  Thus, a given ray may be able to have two or even three different paths traced in one iteration.  However, we average the results and still call this one sample, since it would be inconvenient and slow to track an individual sample count for every pixel.  The result is that the number of samples per second the program can calculate is decreased (since every warp is now running for the full 16 iterations), but those samples of generally of a much higher quality since they themselves are taken to be the average of several other samples, resulting in an overall better looking image in the same amount of runtime.  This difference is noticable, as can be seen in the two images "cornell_box_10s_default.jpg" and "cornell_box_10s_low_divergence.jpg": the latter has much less noise, especially around the bright highlight on the back wall.  To quantify the difference, I added in code to track the average number of rays traced per second by each kernel.  For the cornell box scene, the default kernel averages 171.5 Million Rays per second (MRays/s), whereas the new kernel averages 232.8 MRays/s, a 1.36x speedup.  However, the difference is most noticable on the outdoor scenes: the sphere-only scene improved from 28 MRay/s to 70 MRays/s, and the complex-triangle-mesh scene improved from 18 MRays/s -> 46 MRays/s.  This is an average 2.13x increase over the original kernel, which was already an average 17x faser than the 12-threaded CPU implementation.  Thus, this kernel represents a potential 36x speedup over the 12-threaded CPU implementation.

However, the "rayColorLowerDivergence" kernel is not strictly favorable over the original kernel.  The biggest issue is that it is significantly worse for an interactive display than the naive kernel.  As mentioned above, it takes longer to run and thus generally takes less samples per second than the original kernel, although those samples are of a higher quality (less variance). While this is good for producing a nice-looking image as fast as possible, in terms of interacting with the scene through moving/re-orienting the camera, or even just using the debug-info display, it means a drop in FPS from 14 to 6 on the outdoor scene with spheres, and a drop from 11 FPS to 4 on the outdoor scene with complex-triangle-meshes.  Interestingly enough, the Cornell Box scene actually seems to speed up a bit.  But on the other two scenes, this drop in FPS makes for a significantly worse interactive experience.  For this reason, in the demo recording on YouTube (linked above) I actually use a version of the program compiled with the default kernel to show off interactiveness.

In terms of other optimizations, a BVH tree or similar acceleration structure would go a long way towards making certain geometry-intensive scenes faster.  Also, instead of lowering divergence by having all threads run through a full sixteen iterations of the rayColor method, I could potentially instead compact rays across a block such that all active threads still in the same warps, keeping warp utilization high.  However the current block size is very small for occupancy reasons, due to the kernel using such a large number of registers, so it would currently not be feasible as there would not be enough candidates to merge.  Another possible optimization would be to sort threads based on material before calling the material scatter() and emit() methods, which would also reduce divergence, although the current materials are low enough in number and computational complexity that the overhead of sorting would likely outweight any benefits.

That's all I have for now, although I do intend to keep on working on this project and adding more features, so if you see any opporunties for a potential speedup/improvement I would greatly appreciate sending them my way!  Thanks!
